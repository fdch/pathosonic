\relax 
\citation{anil_camci_2019_3249315}
\citation{rgraham2017}
\citation{giovanni_santini_2019_3249329}
\citation{david_johnson_2019_3249319}
\citation{neupert2017}
\citation{icmc/bbp2372.2010.044}
\citation{KUCHERAMORIN201410}
\citation{gwakefield2014}
\citation{icmc/bbp2372.2010.044}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}PathoSonic}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Goals}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Implementation}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Sound Design}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sound Analysis}{\thepage }\protected@file@percent }
\citation{wbrent2019}
\citation{libpd2019}
\citation{playdots2019}
\newlabel{Screen capture from the Oculus Quest of the plotted feature space at human scale. The analyzed audio is of a 10 second bird.}{{1}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Screen capture from the Oculus Quest of the plotted feature space at human scale. The analyzed audio is of a 10 second bird.}}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Playback}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sequencer}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Spatialization}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Visual Design}{\thepage }\protected@file@percent }
\newlabel{A participant performing PathoSonic. Other than to display the participant's view on screen, the experience is completely wireless.}{{2}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A participant performing PathoSonic. Other than to display the participant's view on screen, the experience is completely wireless.}}{\thepage }\protected@file@percent }
\newlabel{PathoSonic - First Iteration. We began an early exploration by experimenting with sound performance in Virtual Reality (VR) by using the participant's movement in space as the virtual instrument: https://youtu.be/aKzH-xeEbCA}{{2.2.1}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces PathoSonic - First Iteration. We began an early exploration by experimenting with sound performance in Virtual Reality (VR) by using the participant's movement in space as the virtual instrument: https://youtu.be/aKzH-xeEbCA}}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Performance}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Conclusions and Future Work}{\thepage }\protected@file@percent }
\newlabel{PathoSonic - Second Iteration. In this early iteration of the Virtual Reality (VR) experience, participants could change the visualization through the Oculus Touch controller input. The audio was not recorded fort this video: https://youtu.be/aT95KLiOKP4}{{2.2.1}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces PathoSonic - Second Iteration. In this early iteration of the Virtual Reality (VR) experience, participants could change the visualization through the Oculus Touch controller input. The audio was not recorded fort this video: https://youtu.be/aT95KLiOKP4}}{\thepage }\protected@file@percent }
\bibstyle{abbrv}
\bibdata{pathosonic}
\bibcite{giovanni_santini_2019_3249329}{1}
\bibcite{anil_camci_2019_3249315}{2}
\bibcite{david_johnson_2019_3249319}{3}
\bibcite{icmc/bbp2372.2010.044}{4}
\bibcite{wbrent2019}{5}
\bibcite{libpd2019}{6}
\bibcite{rgraham2017}{7}
\bibcite{KUCHERAMORIN201410}{8}
\bibcite{neupert2017}{9}
\bibcite{playdots2019}{10}
\bibcite{gwakefield2014}{11}
\newlabel{PathoSonic - Third Iteration. A participant can change the sound visualization through a user interface that can be toggled on and off. This interface switches between features and plotting in color space (above: r,g, and b) and in 3d space (below: x,y,and z)}{{2.2.2}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces PathoSonic - Third Iteration. A participant can change the sound visualization through a user interface that can be toggled on and off. This interface switches between features and plotting in color space (above: r,g, and b) and in 3d space (below: x,y,and z)}}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Acknowledgments}{\thepage }\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}References}{\thepage }\protected@file@percent }
\newlabel{PathoSonic - Fourth Iteration. This iteration of the experience is only meant to show sound interaction using only Mouse input. This is not the full Virtual Reality (VR) experience since it does not use the Oculus and its controllers: https://youtu.be/nnvPOeIh_fY}{{2.2.3}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces PathoSonic - Fourth Iteration. This iteration of the experience is only meant to show sound interaction using only Mouse input. This is not the full Virtual Reality (VR) experience since it does not use the Oculus and its controllers: https://youtu.be/nnvPOeIh\_fY}}{\thepage }\protected@file@percent }
