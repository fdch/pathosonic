PathoSonic: Performing Sound In Virtual Reality Feature Space

PathoSonic is a VR experience that enables a participant to visualize and perform a sound file based on timbre feature descriptors displayed in space. The name comes from the different paths the participant can create through their sonic explorations. The goal of this research is to leverage affordances of virtual reality technology to visualize sound through different levels of performance-based interactivity that immerses the participant's body in a spatial virtual environment. Through implementation of a multi-sensory experience, including visual aesthetics, sound, and haptic feedback, we explore inclusive approaches to sound visualization, making it more accessible to a wider audience including those with hearing, and mobility impairments. 

This research was made at ACCAD with the gracious participation of Taylor Olsen, and the guidance and support by Dr. Marc Ainger and the ACCAD team. 

PathoSonic is a collaboration between Shadrick Addy and Fede Camara Halac held at the Advanced Computing Center for the Arts and Design of The Ohio State University (2019-2020).  

This video and other materials were made for a poster presentation at NIME 2020 - https://nime2020.bcu.ac.uk

The paper and code are available via GitHub - https://github.com/fdch/pathosonic